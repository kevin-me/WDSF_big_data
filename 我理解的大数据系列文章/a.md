# 大数据的认知和思考
> 大数据无疑是现在最火的词，可能大家并没有深入的了解它。现在人们正在处于一个信息爆炸的时代，我们每个人时时刻刻的都在产生数据，那我们产生的数据到底是什么呢？
其实主要来自于我们的智能电子设备 手机、 电脑、 平板 等 例如 手机刷淘宝的每一次点击 每一次浏览 刷抖音 看微博 读知乎 以及 每天疫情扫码 等等 每一个人 无时无刻不在
产生数据，全球60亿人口 数据量每天都在指数级别的增长。大家肯定好奇 产生的这些数据 被存储在哪里呢 这些数据要怎么应用呢 以及这些数据对我们有哪些好处呢。 我们带着这些疑问一个问题一个问题的为大家解答。


![](http://image.dbbqb.com/202005151634/675e7c099bf5ed4a0ec965ee93a833c3/v1Q8G)

## 数据的产生和存储
要想解答这个问题，首先我们先揭秘一下数据是如何抓取的，拿手机中我们常用的app来说，数据主要分为 用户操作app产生的数据 （称之为用户行为数据）以及 app本身的业务流程产生的数据 （称之为业务数据）。

 用户操作app产生的数据 设计到一个概念 就是 “埋点”，我们操作app的动作都被 埋点 记录下来的，那么埋点 又是什么呢？ 它是怎么记录的？

 其实 埋点 就是 一种 你看不见的 数据收集方式 ，我给大家举个例子 就清晰了。 拿淘宝登陆动作来讲 ，当你输入用户名 密码 ，在触发点击登陆的按钮时， 你的登陆操作就会被记录一条日志。

 用户A 在某时间某刻， 登陆了淘宝； 再比如 你把喜欢的衣服 加入购物车， 这个操作也会被 预先 设计好的埋点方案 抓取 记录下来 。

![](http://image.dbbqb.com/202005151638/744ec9acedaab267c706037abd7d8b20/qAAgL)

现在我们明白我们的操作数据是被预先设计好的埋点方案抓取走了 那么 接着数据被抓取到哪里去了呢 ？ 

因为存储的方式和存储的介质也多种多样 ，我们列举几个行业能常见的形式。

 1.用户操作数据记录到系统运行的日志文件， 也就是被记录在服务器的文件中。

 2.用户操作数据记录到数据库中 mysql、 redis、 Hbase、 Hdfs 、Elasticsearch  等 Elasticsearch 不建议哟 最近被黑客攻击被盗取大量的用户数据 中国还有50万人被盗取 （热点新闻可以查查）。

 3.用户操作数据入kafKa、 kafka 是个消息队列， 用于实时数据处理。  （大数据处理的常用框架 我最近在学习kafka的源码  kafka 分为 生产者（推荐：源码最值得看 多线程 NIO 设计模式 要掌握 都会设计 很多面试题 也都是在 源码中 里面有很多宝藏 希望大家一起坚持去挖掘） 消费者  服务端  ）

## 数据的使用
这时候就要靠你的想象力了， 其实大数据在技术层面就是个处理大量数据的工具 ，让我们具备了处理大量数据的能力 ，关键 还是在于我们想要解决什么问题 。现在这是社会不在以解决问题为主导的了， 是以提出问题 ，谁能提出好的问题变得越来越关键 。  对未来的社会  是想象力的竞争和创造力的竞争，  然而 痛点 问题 不满 苦难 都孕育着机会 。

  其实大数据不是用来解决问题的， 而是找出数据之间的规律去发现问题 ，从而帮助我们进行决策 和 预测。

  列举目前的一些公司常做的和我知道的项目：

  1.广告公司 利用人们 收看习惯 兴趣类别 物理属性（男 女 年龄 区域 等等 ）等 给人贴标签  通俗的讲 就是 爱看体育类节目的人 推送 体育类型的广告 这就是人们常说的人物画像。

  2.餐饮企业 分析企业 经营数据 每天门店的顾客数量 消费水平 以及 就餐体验 等等， 发现经营中存在的问题 ，比如 菜品库存不够  菜品价格的调整 促销活动的反馈 等等。

 3.打车软件 解决人找不到车，  车找不到人的问题 ， 用来 推荐合理的上车地点。

 4.疫情的检测  分析大量的病例CT影像， 对疑似病例的病毒样本进行全基因组序列分析比对，能够有效防止病毒变异产生的漏检，并将原需数小时的全基因分析流程减少到半小时，大幅提高疑似病例的确诊速度和准确率。

  5.我们每天出行必备的扫二维码， 其实就是把我们去过的地方， 以开始时间 开始地点  结束时间 结束地点 的形式 记录 下来，  一旦 在你的出行轨迹中出现 疫情人员， 你的健康码就会变颜色 都是通过大数据处理。

  所以还是提醒大家 出行多扫码 戴口罩 对自己负责 对大家负责。

![](http://image.dbbqb.com/202005151639/1efdfaad572a9906f8fd6b15a25ad8cb/3xjJp)

## 技术实现
接下来 我们就简单叙述下 （注 涉及到专业内容 简单了解 不懂可以私信我） 分如下几个步骤 ：
 ### 集成数据
  
 ####  数据提取
   挑战:获取源数据是集成过程中的第一步。但是，如果数据源具有不同的格式、结构和类型，则会非常复杂和耗时。而且，一旦提取了数据，就必须在集成之前对其进行转换，使其与目标系统兼容。
      解决方案:最好的方法是创建一个所有源数据定期处理的资源列表。寻找支持从所有这些源提取的集成工具。最好使用支持结构化、非结构化和半结构化源的工具，以简化和简化提取过程。

 #### 数据完整性
   挑战:数据质量是每个数据集成策略的主要关注点。糟糕的数据质量可能是影响整个集成周期的复合问题。处理无效或不正确的数据可能导致错误的分析，如果向下传递，可能会破坏结果。
      解决方案:为了确保正确和准确的数据进入数据管道，在开始项目之前创建一个数据质量管理计划，列出这些步骤可以确保在从开发到处理的数据管道的每个步骤中都避免错误的数据。


 #### 可伸缩性
   挑战:数据异构导致来自不同来源的数据流入统一的系统，最终导致数据量呈指数增长。为了应对这一挑战，组织需要采用健壮的集成解决方案，该方案具有处理大量数据和数据差异的特性，同时又不会影响性能。
    解决方案:预测企业数据增长的程度可以帮助组织选择满足可伸缩性和多样性需求的正确的集成解决方案。在这种情况下，采用分段方法也是有益的，因为一次集成一个数据点。根据总体集成策略评估每个数据点的价值可以帮助确定优先级和计划。
      例如，企业希望合并来自三个不同来源的数据:Salesforce、SQL Server和Excel文件。每个系统中的数据可以归类为独特的数据集，如销售、客户信息和财务数据。确定优先级并一次一个地集成这些数据集可以帮助组织逐步扩展数据处理。
      
 #### 数据的活跃性
   由于数据量巨大，我们需要根据业务类型和用户数据的活跃策略，分别存储 经常访问的 数据 存储到redis中，热点数据隔离存储，不活跃的数据体量比较大的也隔离存储可以选择性价比低的存储介质，提高访问数据的速度，数据会做多个副本 采用异步 并发访问 维持 长连接
 


 #### 技术方案

- logstash作为一个数据管道中间件，支持对各种类型数据的采集与转换，并将数据发送到Hbase 、Hdfs、mysql等数据库中
- 使用sqoop导入数据到Hive、 Hbase 、Hdfs、mysql等数据库中
- 读取数据到kafka中 再把数据消费到 Elasticsearch、  Hive、 Hbase 、Hdfs、mysql

## 系统架构搭建、数学模型建立
分析预测、统计数据生成报表和统计图
现在常用的是spark、kafka、hbase 等，flink 现在比较流行，其实flink 比spark项目开始的早，但是spark 先火了起来，现在 flink 能做spark所有能做的事 而且做的更好 ，背后也有阿里的支撑，很多公司现在也开始改用
     flink来做大数据的处理框架。

   讲一下内部技术的实现：我参加过全国数学建模竞赛，给我的第一感觉就是以前用matlab解决的问题 现在换成了 spark 或者 flink 当然 不是尽然相同的，但是内部处理的原理大同小异。

   都是获取数据 拿到 计算机 内存中 过滤 转换 统计 处理 得到人们想要的结果 ，这只是一些 简单的操作 ，我觉得真正有灵魂 的操作 就是 数学建模 也是最难的地方。

   但是大神 提供了很多开源的 数据分析和机器学习算法库  Python  Pandas 、spark MLlib
     我们需要熟悉 一些常用的算法   线性回归算法、梯度下降策略、逻辑回归算法、决策树算法、集成算法、随机森林、贝叶斯算法 、聚类算法-Kmeans、神经网络,这些我也花了半年的时间去学习。

   https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/

   Koalas，目标是使用 Pandas API 可以直接运行在 Spark，能够支持数据科学家更好的无缝迁移到 Spark。

![](http://image.dbbqb.com/202005151640/059384c2dcee0eb800a9ff667f1ea8c9/LEN7Y)

## 5G 时代的到来推动了什么呢？
   万物互联的世界 产生数据的介质越来越多了 也变得越来越智能 ，  使我们提取数据的速度 越来越快  并发能力 大大提升 ，推动了 大数据和人工智能的进一步发展。


## 大数据跟人工智能有什么关联呢？
   人工智能 是让机器有学习的能力 变得越来越智能 ，机器是如何学习的呢，正是大数据提供大量的训练数据，让机器通过深度学习算法 不断的迭代，不断升级 。

  只要 不断的提供 算法需要的数据，动态调节模型参数 通过验证 反馈，机器就会越来越智能。

  机器人 就能  病毒的检测 、 药物的诊断 、识别你的情绪等等

## 学习的疑问解答


### 大数据的技术那么多，需要全会吗
答案肯定是否定的，框架那么多，版本更新快，自学难度大  但是一些 技术硬实力的东西必须掌握

我们怎么保证自己的优势呢 找到自己研究的方向  也就是研究一个点

在一个点上 研究明白 研究深入  能 解决 问题  成为这个领域的专家 就是自己优势

那怎么寻找研究的方向呢 ？

这个问题好难呀  我也在努力寻找 好的习惯 一定要要坚持 别迷茫别丢了自己  迷失自己应该是这个世界上最糟糕的事了
<center>
<img src="http://image.dbbqb.com/202005151640/426c4259a0b6102be46acd6e8d64602d/jx2xO" style="width: 50%;"></center>


### 一些心得
很多知识 不是学了没有用 是知识你还没机会用到它 跟大家分享下 那些知识是哪里用到的 给大家提个醒 （因为我也很希望有人告诉你 你学的有用 在哪里用到 然而我却是 自己发现的）

第一 基础最重要

第二 jvm调优 flink 的 状态管理 是放在 堆内存的哟    不精通的话 怎么调优处理 内存溢出怎么办

第三 高并发 设计模式 NIO  kafka 生产者源码 都有涉及哟  基础打不牢固 看着很费劲


#### 简单 坚持

读万卷书 不如行万里路 知识还是要学以致用 既要多读书 也要出去找找机会 ，听过大神说过的一句话 所有困难的问题之所有变得简单 是因为 每一天 坚持，失败是一种财富，
简单的人只想我要做什么 怎么做，而反思能让我们做的越来越好

不管你现在的生命是怎么样的，我们一定要有水的精神  像水一样不断地积蓄自己的力量，不断地冲破障碍。
当你发现时机不到的时候，把自己的厚度给积累起来，当有一天时机来临的时候， 你就能够奔腾入海，成就自己的生命。

我们这一生很短，我们终将会失去它，所以不妨大胆一点， 爱一个人，攀一座山，追一次梦。

---

欢迎大家留言评论，原创技术文章第一时间推送。


<center>
<img src="http://image.dbbqb.com/202005151641/76a88ddf683123f701b717bdeda45676/ewyKO" style="width: 50%;"></center>