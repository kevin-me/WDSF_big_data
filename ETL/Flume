官方文档 ：

http://archive.cloudera.com/cdh5/cdh/5/flume-ng-1.6.0-cdh5.14.2/FlumeUserGuide.html


flume 使用 说明  必看

Flume可以采集文件，socket数据包、文件、文件夹、kafka等各种形式源数据，又可以将采集到的数据(下沉sink)输出到HDFS、hbase、hive、kafka等众多外部存储系统中

- Flume分布式系统中最核心的角色是agent，flume采集系统就是由一个个agent所连接起来形成的
- 每一个agent相当于一个数据传递员，内部有三个组件：
  - Source：采集组件，用于跟数据源对接，以获取数据
  - Sink：下沉组件，用于往下一级agent传递数据或者往最终存储系统传递数据
  - Channel：传输通道组件，用于从source将数据传递到sink

  理解event  传输 单元   超过 1024  放入 另一个event


案例 ： 1. 采集目录到HDFS  某服务器的某特定目录下，会不断产生新的文件，每当有新文件出现，就需要把文件采集到HDFS中去

       2. 采集文件到HDFS   用log4j生成的日志，日志内容不断增加，需要把追加到日志文件中的数据实时采集到hdfs

       3.flume的tail-dir source实现断点续传功能

       4.两个agent级联

       5.更多source和sink组件

       6. flume综合案例之静态拦截器使用

       7. flume综合案例之自定义拦截器使用

       8.   flume自定义source                从MySQL中获取数据传输到HDFS或者其他存储框架，所以此时需要我们自己实现MySQLSource。

       9.flume自定义sink  需要把接受到的数据按照规则进行过滤之后写入到某张mysql表中

高可用Flum-NG配置案例failover

flume的负载均衡load balancer




# 定义这个agent中各组件的名字
a1.sources = r1
a1.sinks = k1
a1.channels = c1
# 描述和配置source组件：r1
a1.sources.r1.type = netcat
a1.sources.r1.bind = 192.168.52.120
a1.sources.r1.port = 44444

# 描述和配置sink组件：k1
a1.sinks.k1.type = logger

# 描述和配置channel组件，此处使用是内存缓存的方式
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# 描述和配置source  channel   sink之间的连接关系
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

- 某服务器的某特定目录下，会不断产生新的文件，每当有新文件出现，就需要把文件采集到HDFS中去
- 根据需求，首先定义以下3大要素
  - 数据源组件，即source ——监控文件目录 : spooldir

- 采集需求：比如业务系统使用log4j生成的日志，日志内容不断增加，需要把追加到日志文件中的数据实时采集到hdfs
- 根据需求，首先定义以下3大要素
  - 采集源，即source——监控文件内容更新 : exec ‘tail -F file’

采集需求，使用tail-dirsource监听某个目录下的多个文件，并且实现文件的断点续传功能  flume 1.7之后

高可用Flum-NG配置案例failover
##set failover
agent1.sinkgroups.g1.processor.type = failover
agent1.sinkgroups.g1.processor.priority.k1 = 10
agent1.sinkgroups.g1.processor.priority.k2 = 1
agent1.sinkgroups.g1.processor.maxpenalty = 10000

注意 从下 往上启动
flume的负载均衡load balancer
#set failover
a1.sinkgroups.g1.processor.type = load_balance
a1.sinkgroups.g1.processor.backoff = true
a1.sinkgroups.g1.processor.selector = round_robin
a1.sinkgroups.g1.processor.selector.maxTimeOut=10000

注意 从下 往上启动


静态拦截器

a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = static
##  static拦截器的功能就是往采集到的数据的header中插入自己定## 义的key-value对
a1.sources.r1.interceptors.i1.key = type
a1.sources.r1.interceptors.i1.value = access

a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path=hdfs://192.168.52.100:8020/source/logs/%{type}/%Y%m%d
a1.sinks.k1.hdfs.filePrefix =events
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.writeFormat = Text


自定义拦截器
MyInterceptor implements Interceptor {

   *
         * 单个event拦截逻辑
         */
    public Event intercept(Event event) {
        if (event == null) {
            return null;
        }
        try {
            String line = new String(event.getBody(), Charsets.UTF_8);
            String[] fields = line.split(",");

            String newLine = "";
            for (int i = 0; i < fields.length; i++) {
                //字符串数字转换成int
                int encryptedField = Integer.parseInt(encrypted_field_index);
                int outIndex = Integer.parseInt(out_index);

                if (i == encryptedField) {
                     newLine+=md5(fields[i])+",";
                }else if(i !=outIndex) {
                    newLine+=fields[i]+",";
                }
            }
            newLine=newLine.substring(0,newLine.length()-1);

              event.setBody(newLine.getBytes(Charsets.UTF_8));
            return event;
        } catch (Exception e) {
            return event;
        }

    }
}

flume自定义source

1. 根据官方说明自定义mysqlsource需要继承AbstractSource类并实现Configurable和PollableSource接口。
2. 实现对应的方法
   1. configure(Context context)
      初始化context
   2. process()
      从mysql表中获取数据，然后把数据封装成event对象写入到channel，该方法被一直调用
   3. stop()
      关闭相关资源
flume自定义sink

1. 根据官方说明自定义MysqlSink需要继承AbstractSink类并实现Configurable
2. 实现对应的方法
   1. configure(Context context)
      初始化context
   2. start()
      启动准备操作
   3. process()
      从channel获取数据，然后解析之后，保存在mysql表中
   4. stop()
      关闭相关资源

